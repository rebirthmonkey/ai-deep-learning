#  LeNet

回想一下，之前我们将 Softmax 回归模型和 MLP 应用于 Fashion-MNIST 数据集中的服装图片。为了能够应用 Softmax 回归和 MLP，我们首先将每个大小为 $28\times28$ 的图像展平为一个 784 维的固定长度的一维向量，然后用全连接层对其进行处理。而现在，我们已经掌握了 CNN 的处理方法，我们可以在图像中保留空间结构。同时，用卷积层代替全连接层的另一个好处是：模型更简洁、所需的参数更少。

LeNet 是最早发布的 CNN 之一，因其在计算机视觉任务中的高效性能而受到广泛关注。这个模型是由 AT&T 贝尔实验室的研究员 Yann LeCun 在 1989 年提出的（并以其命名），目的是识别图像中的手写数字。当时，Yann LeCun 发表了第一篇通过反向传播成功训练 CNN 的研究，这项工作代表了十多年来神经网络研究开发的成果。LeNet 被广泛用于 ATM 机中，帮助识别处理支票的数字。时至今日，一些自动取款机仍在运行 Yann LeCun 和他的同事 Leon Bottou 在上世纪 90 年代写的代码。

## 网络结构

LeNet 输入尺寸是 $32*32$，它输入的是灰度的图像，整个的网络结构是：

* 输入层：$32 \times 32$ 单通道
  
* 卷积层：
  * 卷积层：$5\times 5$ 卷积核
  * sigmoid() 激活函数：虽然ReLU和最大汇聚层更有效，但它们在20世纪90年代还没有出现
  * 输出通道：6 个

* 池化层：
  * $2\times2$ 池化操作（步幅2）
  * 平均池化

* 卷积层：
  * 卷积层：$5\times 5$ 卷积核
  * sigmoid() 激活函数：
  * 输出通道：16 个

* 池化层：
  * $2\times2$ 池化操作（步幅2）
  * 平均池化

* 全连接层：
  * 120 输出

* 全连接层：
  * 84 输出

* 输出层：
  * 10 输出
  * Softmax() 激活函数


![lenet](figures/lenet.svg)
